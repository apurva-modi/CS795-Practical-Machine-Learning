{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation System\n",
    "Movie recommendation system using MovieLen 100K dataset. Comparison between Matrix Factorization, Non-negative Matrix Factorization, and Neural Network.\n",
    "\n",
    "Code source from\n",
    "https://nipunbatra.github.io/blog/2017/recommend-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Inspect Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"ml-100k/u.data\",sep='\\t',names=\"user_id,item_id,rating,timestamp\".split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.user_id.unique()), len(dataset.item_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.user_id = dataset.user_id.astype('category').cat.codes.values\n",
    "dataset.item_id = dataset.item_id.astype('category').cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195</td>\n",
       "      <td>241</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165</td>\n",
       "      <td>345</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      195      241       3  881250949\n",
       "1      185      301       3  891717742\n",
       "2       21      376       1  878887116\n",
       "3      243       50       2  880606923\n",
       "4      165      345       1  886397596"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(dataset, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation using Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from IPython.display import SVG\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "n_users, n_movies = len(dataset.user_id.unique()), len(dataset.item_id.unique())\n",
    "n_latent_factors = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_input = tensorflow.keras.layers.Input(shape=[1],name='Item')\n",
    "movie_embedding = tensorflow.keras.layers.Embedding(n_movies + 1, n_latent_factors, name='Movie-Embedding')(movie_input)\n",
    "movie_vec = tensorflow.keras.layers.Flatten(name='FlattenMovies')(movie_embedding)\n",
    "\n",
    "user_input = tensorflow.keras.layers.Input(shape=[1],name='User')\n",
    "user_vec = tensorflow.keras.layers.Flatten(name='FlattenUsers')(tensorflow.keras.layers.Embedding(n_users + 1, n_latent_factors,name='User-Embedding')(user_input))\n",
    "\n",
    "prod = tensorflow.keras.layers.dot([movie_vec, user_vec], axes=1, name='DotProduct')\n",
    "\n",
    "model = tensorflow.keras.Model([user_input, movie_input], prod)\n",
    "model.compile('adam', 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVG(model_to_dot(model,  show_shapes=True, show_layer_names=True, rankdir='HB').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Item (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "User (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Movie-Embedding (Embedding)     (None, 1, 3)         5049        Item[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "User-Embedding (Embedding)      (None, 1, 3)         2832        User[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "FlattenMovies (Flatten)         (None, 3)            0           Movie-Embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FlattenUsers (Flatten)          (None, 3)            0           User-Embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "DotProduct (Dot)                (None, 1)            0           FlattenMovies[0][0]              \n",
      "                                                                 FlattenUsers[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 7,881\n",
      "Trainable params: 7,881\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'pandas.core.series.Series'>\"}), <class 'NoneType'>\n",
      "Train on 80000 samples\n",
      "Epoch 1/100\n",
      "80000/80000 [==============================] - 3s 36us/sample - loss: 12.0279\n",
      "Epoch 2/100\n",
      "80000/80000 [==============================] - 3s 34us/sample - loss: 4.5626\n",
      "Epoch 3/100\n",
      "80000/80000 [==============================] - 3s 34us/sample - loss: 1.9386\n",
      "Epoch 4/100\n",
      "80000/80000 [==============================] - 3s 34us/sample - loss: 1.3150\n",
      "Epoch 5/100\n",
      "80000/80000 [==============================] - 2s 26us/sample - loss: 1.0853\n",
      "Epoch 6/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.9855\n",
      "Epoch 7/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.93780s - loss: 0.937\n",
      "Epoch 8/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.9127\n",
      "Epoch 9/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8978\n",
      "Epoch 10/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8884\n",
      "Epoch 11/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8818\n",
      "Epoch 12/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8774\n",
      "Epoch 13/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8740\n",
      "Epoch 14/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8712\n",
      "Epoch 15/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8685\n",
      "Epoch 16/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8669\n",
      "Epoch 17/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8652\n",
      "Epoch 18/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8640\n",
      "Epoch 19/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8629\n",
      "Epoch 20/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8619\n",
      "Epoch 21/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8603\n",
      "Epoch 22/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8597\n",
      "Epoch 23/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8582\n",
      "Epoch 24/100\n",
      "80000/80000 [==============================] - 2s 23us/sample - loss: 0.8570\n",
      "Epoch 25/100\n",
      "80000/80000 [==============================] - 2s 23us/sample - loss: 0.8559\n",
      "Epoch 26/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8543\n",
      "Epoch 27/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8525\n",
      "Epoch 28/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8509\n",
      "Epoch 29/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8488\n",
      "Epoch 30/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8461\n",
      "Epoch 31/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8432\n",
      "Epoch 32/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8401\n",
      "Epoch 33/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8358\n",
      "Epoch 34/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8315\n",
      "Epoch 35/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8264\n",
      "Epoch 36/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8213\n",
      "Epoch 37/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8156\n",
      "Epoch 38/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8093\n",
      "Epoch 39/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.8036\n",
      "Epoch 40/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7975\n",
      "Epoch 41/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7918\n",
      "Epoch 42/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7865\n",
      "Epoch 43/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7808\n",
      "Epoch 44/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7766\n",
      "Epoch 45/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7721\n",
      "Epoch 46/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7680\n",
      "Epoch 47/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7645\n",
      "Epoch 48/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7611\n",
      "Epoch 49/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7583\n",
      "Epoch 50/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7557\n",
      "Epoch 51/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7534\n",
      "Epoch 52/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7511\n",
      "Epoch 53/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7488\n",
      "Epoch 54/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7471\n",
      "Epoch 55/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7452\n",
      "Epoch 56/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7436\n",
      "Epoch 57/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7421\n",
      "Epoch 58/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7408\n",
      "Epoch 59/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7392\n",
      "Epoch 60/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7380\n",
      "Epoch 61/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7370\n",
      "Epoch 62/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7358\n",
      "Epoch 63/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7345\n",
      "Epoch 64/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7338\n",
      "Epoch 65/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7327\n",
      "Epoch 66/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7319\n",
      "Epoch 67/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.73090s - l\n",
      "Epoch 68/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7303\n",
      "Epoch 69/100\n",
      "80000/80000 [==============================] - 2s 23us/sample - loss: 0.7295\n",
      "Epoch 70/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7288\n",
      "Epoch 71/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7281\n",
      "Epoch 72/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7274\n",
      "Epoch 73/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7269\n",
      "Epoch 74/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7263\n",
      "Epoch 75/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7255\n",
      "Epoch 76/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7251\n",
      "Epoch 77/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7245\n",
      "Epoch 78/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7242\n",
      "Epoch 79/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7236\n",
      "Epoch 80/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7233\n",
      "Epoch 81/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7228\n",
      "Epoch 82/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.72200s - loss: 0.\n",
      "Epoch 83/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7221\n",
      "Epoch 84/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7214\n",
      "Epoch 85/100\n",
      "80000/80000 [==============================] - 2s 23us/sample - loss: 0.7212\n",
      "Epoch 86/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7208\n",
      "Epoch 87/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7204\n",
      "Epoch 88/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7200\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7196\n",
      "Epoch 90/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7194\n",
      "Epoch 91/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7190\n",
      "Epoch 92/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7187\n",
      "Epoch 93/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7184\n",
      "Epoch 94/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7183\n",
      "Epoch 95/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7177\n",
      "Epoch 96/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7176\n",
      "Epoch 97/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7172\n",
      "Epoch 98/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7174\n",
      "Epoch 99/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7171\n",
      "Epoch 100/100\n",
      "80000/80000 [==============================] - 2s 22us/sample - loss: 0.7166\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([train.user_id, train.item_id], train.rating, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Train Error')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(history.history['loss']).plot(logy=True)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Train Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'pandas.core.series.Series'>\"}), <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "y_hat = np.round(model.predict([test.user_id, test.item_id]),0)\n",
    "y_true = test.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6946"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1683.000000</td>\n",
       "      <td>1683.000000</td>\n",
       "      <td>1683.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.975810</td>\n",
       "      <td>0.851396</td>\n",
       "      <td>0.937998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.455443</td>\n",
       "      <td>0.518912</td>\n",
       "      <td>0.461832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.619111</td>\n",
       "      <td>-1.036764</td>\n",
       "      <td>-0.932491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.648488</td>\n",
       "      <td>0.502150</td>\n",
       "      <td>0.612579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.984188</td>\n",
       "      <td>0.852441</td>\n",
       "      <td>0.973312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.303464</td>\n",
       "      <td>1.236784</td>\n",
       "      <td>1.280570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.542449</td>\n",
       "      <td>2.325980</td>\n",
       "      <td>2.482553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2\n",
       "count  1683.000000  1683.000000  1683.000000\n",
       "mean      0.975810     0.851396     0.937998\n",
       "std       0.455443     0.518912     0.461832\n",
       "min      -0.619111    -1.036764    -0.932491\n",
       "25%       0.648488     0.502150     0.612579\n",
       "50%       0.984188     0.852441     0.973312\n",
       "75%       1.303464     1.236784     1.280570\n",
       "max       2.542449     2.325980     2.482553"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_embedding_learnt = model.get_layer(name='Movie-Embedding').get_weights()[0]\n",
    "pd.DataFrame(movie_embedding_learnt).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1683, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_embedding_learnt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.081534</td>\n",
       "      <td>1.187131</td>\n",
       "      <td>1.117269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.513242</td>\n",
       "      <td>0.430761</td>\n",
       "      <td>0.547319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.242091</td>\n",
       "      <td>-0.749022</td>\n",
       "      <td>-0.606336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.768188</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.745218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.093960</td>\n",
       "      <td>1.217144</td>\n",
       "      <td>1.106681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.421018</td>\n",
       "      <td>1.495152</td>\n",
       "      <td>1.491973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.541045</td>\n",
       "      <td>2.396723</td>\n",
       "      <td>2.880352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           1           2\n",
       "count  944.000000  944.000000  944.000000\n",
       "mean     1.081534    1.187131    1.117269\n",
       "std      0.513242    0.430761    0.547319\n",
       "min     -1.242091   -0.749022   -0.606336\n",
       "25%      0.768188    0.921875    0.745218\n",
       "50%      1.093960    1.217144    1.106681\n",
       "75%      1.421018    1.495152    1.491973\n",
       "max      2.541045    2.396723    2.880352"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embedding_learnt = model.get_layer(name='User-Embedding').get_weights()[0]\n",
    "pd.DataFrame(user_embedding_learnt).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.18353   ,  1.7226923 ,  0.5825984 ],\n",
       "       [ 0.53640217,  1.8114469 ,  0.97647816],\n",
       "       [ 0.97251827,  1.0810235 ,  0.6602126 ],\n",
       "       ...,\n",
       "       [ 1.058401  ,  1.0863191 ,  1.7012861 ],\n",
       "       [ 1.5982289 ,  1.0798706 ,  0.7811139 ],\n",
       "       [-0.01372885,  0.00786493, -0.04854197]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embedding_learnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the completed matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = user_embedding_learnt.dot(np.transpose(movie_embedding_learnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.8766613e+00,  2.9156163e+00,  2.9493024e+00, ...,\n",
       "         3.6652682e+00,  3.1490128e+00, -4.8320532e-02],\n",
       "       [ 3.8951097e+00,  3.0158050e+00,  2.6182876e+00, ...,\n",
       "         3.4959335e+00,  2.9952102e+00, -2.2179427e-02],\n",
       "       [ 3.0459712e+00,  2.4333739e+00,  2.4123340e+00, ...,\n",
       "         2.8661444e+00,  2.4286740e+00, -4.5698766e-02],\n",
       "       ...,\n",
       "       [ 4.5318980e+00,  3.9877856e+00,  3.5383682e+00, ...,\n",
       "         4.0978942e+00,  3.3923197e+00, -6.5116011e-02],\n",
       "       [ 3.7991962e+00,  3.1066375e+00,  3.2724216e+00, ...,\n",
       "         3.6637015e+00,  3.0820866e+00, -7.7531345e-02],\n",
       "       [-6.9191396e-02, -7.4924372e-02, -5.9450738e-02, ...,\n",
       "        -5.9469610e-02, -4.5924492e-02,  1.4526668e-03]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation using Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_latent_factors_user = 5\n",
    "n_latent_factors_movie = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_input = tensorflow.keras.layers.Input(shape=[1],name='Item')\n",
    "movie_embedding = tensorflow.keras.layers.Embedding(n_movies + 1, n_latent_factors_movie, name='Movie-Embedding')(movie_input)\n",
    "movie_vec = tensorflow.keras.layers.Flatten(name='FlattenMovies')(movie_embedding)\n",
    "movie_vec = tensorflow.keras.layers.Dropout(0.2)(movie_vec)\n",
    "\n",
    "\n",
    "user_input = tensorflow.keras.layers.Input(shape=[1],name='User')\n",
    "user_vec = tensorflow.keras.layers.Flatten(name='FlattenUsers')(tensorflow.keras.layers.Embedding(n_users + 1, n_latent_factors_user,name='User-Embedding')(user_input))\n",
    "user_vec = tensorflow.keras.layers.Dropout(0.2)(user_vec)\n",
    "\n",
    "\n",
    "concat = tensorflow.keras.layers.Concatenate(name='Concat')([movie_vec, user_vec])\n",
    "concat_dropout = tensorflow.keras.layers.Dropout(0.2)(concat)\n",
    "dense = tensorflow.keras.layers.Dense(200,name='FullyConnected')(concat)\n",
    "dropout_1 = tensorflow.keras.layers.Dropout(0.2,name='Dropout')(dense)\n",
    "dense_2 = tensorflow.keras.layers.Dense(100,name='FullyConnected-1')(concat)\n",
    "dropout_2 = tensorflow.keras.layers.Dropout(0.2,name='Dropout')(dense_2)\n",
    "dense_3 = tensorflow.keras.layers.Dense(50,name='FullyConnected-2')(dense_2)\n",
    "dropout_3 = tensorflow.keras.layers.Dropout(0.2,name='Dropout')(dense_3)\n",
    "dense_4 = tensorflow.keras.layers.Dense(20,name='FullyConnected-3', activation='relu')(dense_3)\n",
    "\n",
    "\n",
    "result = tensorflow.keras.layers.Dense(1, activation='relu',name='Activation')(dense_4)\n",
    "adam = Adam(lr=0.005)\n",
    "model = tensorflow.keras.Model([user_input, movie_input], result)\n",
    "model.compile(optimizer=adam,loss= 'mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Item (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "User (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Movie-Embedding (Embedding)     (None, 1, 8)         13464       Item[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "User-Embedding (Embedding)      (None, 1, 5)         4720        User[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "FlattenMovies (Flatten)         (None, 8)            0           Movie-Embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FlattenUsers (Flatten)          (None, 5)            0           User-Embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 8)            0           FlattenMovies[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 5)            0           FlattenUsers[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Concat (Concatenate)            (None, 13)           0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "FullyConnected-1 (Dense)        (None, 100)          1400        Concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FullyConnected-2 (Dense)        (None, 50)           5050        FullyConnected-1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "FullyConnected-3 (Dense)        (None, 20)           1020        FullyConnected-2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Activation (Dense)              (None, 1)            21          FullyConnected-3[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 25,675\n",
      "Trainable params: 25,675\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'pandas.core.series.Series'>\"}), <class 'NoneType'>\n",
      "Train on 80000 samples\n",
      "Epoch 1/100\n",
      "80000/80000 [==============================] - 4s 54us/sample - loss: 0.8226\n",
      "Epoch 2/100\n",
      "80000/80000 [==============================] - 4s 48us/sample - loss: 0.7676\n",
      "Epoch 3/100\n",
      "80000/80000 [==============================] - 4s 48us/sample - loss: 0.7535\n",
      "Epoch 4/100\n",
      "80000/80000 [==============================] - 4s 48us/sample - loss: 0.7431\n",
      "Epoch 5/100\n",
      "80000/80000 [==============================] - 4s 48us/sample - loss: 0.7337\n",
      "Epoch 6/100\n",
      "80000/80000 [==============================] - 4s 48us/sample - loss: 0.7295\n",
      "Epoch 7/100\n",
      "80000/80000 [==============================] - 4s 48us/sample - loss: 0.7241\n",
      "Epoch 8/100\n",
      "80000/80000 [==============================] - 4s 48us/sample - loss: 0.7212\n",
      "Epoch 9/100\n",
      "80000/80000 [==============================] - 4s 48us/sample - loss: 0.7195\n",
      "Epoch 10/100\n",
      "80000/80000 [==============================] - 4s 49us/sample - loss: 0.7176\n",
      "Epoch 11/100\n",
      "80000/80000 [==============================] - 4s 48us/sample - loss: 0.7136\n",
      "Epoch 12/100\n",
      "80000/80000 [==============================] - 3s 40us/sample - loss: 0.7120\n",
      "Epoch 13/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.7053\n",
      "Epoch 14/100\n",
      "80000/80000 [==============================] - 2s 31us/sample - loss: 0.7045\n",
      "Epoch 15/100\n",
      "80000/80000 [==============================] - 2s 31us/sample - loss: 0.6997\n",
      "Epoch 16/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.7006\n",
      "Epoch 17/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6954\n",
      "Epoch 18/100\n",
      "80000/80000 [==============================] - 3s 31us/sample - loss: 0.6945\n",
      "Epoch 19/100\n",
      "80000/80000 [==============================] - 2s 31us/sample - loss: 0.6944\n",
      "Epoch 20/100\n",
      "80000/80000 [==============================] - 2s 31us/sample - loss: 0.6902\n",
      "Epoch 21/100\n",
      "80000/80000 [==============================] - 2s 31us/sample - loss: 0.6911\n",
      "Epoch 22/100\n",
      "80000/80000 [==============================] - 3s 31us/sample - loss: 0.6901\n",
      "Epoch 23/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6894\n",
      "Epoch 24/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6869\n",
      "Epoch 25/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6871\n",
      "Epoch 26/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6857\n",
      "Epoch 27/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6839\n",
      "Epoch 28/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6858\n",
      "Epoch 29/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6850\n",
      "Epoch 30/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6839\n",
      "Epoch 31/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6828\n",
      "Epoch 32/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6818\n",
      "Epoch 33/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6837\n",
      "Epoch 34/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6801\n",
      "Epoch 35/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6810\n",
      "Epoch 36/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6801\n",
      "Epoch 37/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6809\n",
      "Epoch 38/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6782\n",
      "Epoch 39/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6795\n",
      "Epoch 40/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6806\n",
      "Epoch 41/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6795\n",
      "Epoch 42/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6802\n",
      "Epoch 43/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6775\n",
      "Epoch 44/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6790\n",
      "Epoch 45/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6792\n",
      "Epoch 46/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6792\n",
      "Epoch 47/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6782\n",
      "Epoch 48/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6784\n",
      "Epoch 49/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6785\n",
      "Epoch 50/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6760\n",
      "Epoch 51/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6768\n",
      "Epoch 52/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6757\n",
      "Epoch 53/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6783\n",
      "Epoch 54/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6755\n",
      "Epoch 55/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6784\n",
      "Epoch 56/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6779\n",
      "Epoch 57/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6760\n",
      "Epoch 58/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6766\n",
      "Epoch 59/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6756\n",
      "Epoch 60/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6760\n",
      "Epoch 61/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6749\n",
      "Epoch 62/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6745\n",
      "Epoch 63/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6746\n",
      "Epoch 64/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6740\n",
      "Epoch 65/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6744\n",
      "Epoch 66/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6756\n",
      "Epoch 67/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6741\n",
      "Epoch 68/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6757\n",
      "Epoch 69/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6753\n",
      "Epoch 70/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6752\n",
      "Epoch 71/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6745\n",
      "Epoch 72/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6732\n",
      "Epoch 73/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6730\n",
      "Epoch 74/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6740\n",
      "Epoch 75/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.67430s - loss: \n",
      "Epoch 76/100\n",
      "80000/80000 [==============================] - 3s 33us/sample - loss: 0.6745\n",
      "Epoch 77/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6761\n",
      "Epoch 78/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6739\n",
      "Epoch 79/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6741\n",
      "Epoch 80/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6746\n",
      "Epoch 81/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6730\n",
      "Epoch 82/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6750\n",
      "Epoch 83/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6750\n",
      "Epoch 84/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6731\n",
      "Epoch 85/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6739\n",
      "Epoch 86/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6714\n",
      "Epoch 87/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6748\n",
      "Epoch 88/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6732\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6722\n",
      "Epoch 90/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6760\n",
      "Epoch 91/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6738\n",
      "Epoch 92/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6746\n",
      "Epoch 93/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6735\n",
      "Epoch 94/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6718\n",
      "Epoch 95/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6718\n",
      "Epoch 96/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6741\n",
      "Epoch 97/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6738\n",
      "Epoch 98/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6715\n",
      "Epoch 99/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6736\n",
      "Epoch 100/100\n",
      "80000/80000 [==============================] - 3s 32us/sample - loss: 0.6739\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([train.user_id, train.item_id], train.rating, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'pandas.core.series.Series'>\"}), <class 'NoneType'>\n",
      "0.6964\n"
     ]
    }
   ],
   "source": [
    "y_hat_2 = np.round(model.predict([test.user_id, test.item_id]),0)\n",
    "print(mean_absolute_error(y_true, y_hat_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
